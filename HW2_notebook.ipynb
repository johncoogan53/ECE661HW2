{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. True/False Questions (15 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1.1 (3pts)** Any type of data augmentation techniques are always beneficial for deep learning\n",
    "applications.\n",
    "\n",
    "> False, data augmentation techniques are not alwaays beneficial. For instance, flipping elements of the mnist dataset can turn a 9 into a 6 while the data is still labeled as a 9. This is not beneficial for the model because now it has what looks like a 6 labeled as a 9 which will cause training issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1.2 (3pts)** If we do not use both batch normalization and dropout, CNN training converges\n",
    "much slower.\n",
    "\n",
    ">False, depending on how dropout is employed, it can increase either the training time or the inference time. Depending on when dropout scaling is applied, one could see reduced convergence time in training. Batch normalization will normally decrease the convergence time of a CNN though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1.3 (3pts)** Dropout is a common technique to combat overfitting. If L-normalizations are\n",
    "included alongside dropout, the performance will be even better.\n",
    "\n",
    ">False, dropout is a technique to combat overfitting. It accomplishes this by randomly setting a fraction of the neurons to zero. This forces the remaining neurons to pick up the feature representations that the dropped neurons were responsible for. The remaining neurons contribute to the output of the network in a naive way that prevents overfitting. That said, dropout does not always cooperate well with L-norm regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1.4 (3pts)** During training, the Lasso (L1) regularizer causes the model to have a higher\n",
    "sparsity compared to Ridge (L2) regularizer.\n",
    "\n",
    "> True, L1 regularization yields sparce solutions which should be used for compact models with high compression rate. L2 regularization yields more stable results without too much training effort. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1.5 (3pts)** The shortcut connections in ResNets result in smoother loss surface.\n",
    "\n",
    "> True, the shortcut connections in ResNet results in a smoother loss surface. By applying residual learning and forwarding inputs via bypass further into the architecture, the gradient can be more directly propagated to earlier layers. This helps to prevent the vanishing gradient problem and allows for smoother loss surfaces. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Computation Questions (15 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2.1 (3pts)** Consider a 100x100 RGB Image as an input. If the first hidden layer consists of 100\n",
    "neurons, and each neuron is fully connected to the input, how many parameters does this hidden layer\n",
    "have including both the weights and the bias parameters?\n",
    "\n",
    "The number of inputs is the size of the image multiplied by the channels (R,G,B):\n",
    "\n",
    "$100*100*3 = 30,000$\n",
    "\n",
    "Each neuron will have a weight for each input and a bias term. Therefore, the number of parameters for the hidden layer is:\n",
    "\n",
    "$30,000*100 + 100 = 3,000,100$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2.2 (3pts)** Consider the same 100x100 RGB Image as an input. If you use a convolution layer\n",
    "with 100 filters each with size 3x3, how many parameters does this hidden layer have including both the\n",
    "weights and the bias parameters ?\n",
    "\n",
    "Convolutional Layer Shape Rules:\n",
    "\n",
    "- Number of filters N\n",
    "- Convolutional kernel size K\n",
    "- Stride for convolution S\n",
    "- Padding for each border P\n",
    "\n",
    "Output feature map: $C_{2} \\times H_{2} \\times W_{2}$ , where\n",
    "\n",
    "$W_{2} = [ \\frac{W_{1}-K+2P}{S}]+1$\n",
    "\n",
    "$H_{2} = [ \\frac{H_{1}-K+2P}{S}]+1$\n",
    "\n",
    "$C_{2} = N$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of filters: $N = 100$\n",
    "\n",
    "convolutional kernel size: $K = 3$\n",
    "\n",
    "Stride for convolution: $S = 1$ (Assumption)\n",
    "\n",
    "Padding for each border: $P = 0$ (Assumption)\n",
    "\n",
    "$W_{2} = [ \\frac{100-3+2*0}{1}]+1 = 98$\n",
    "\n",
    "$H_{2} = [ \\frac{100-3+2*0}{1}]+1 = 98$\n",
    "\n",
    "$C_{2} = 100$\n",
    "\n",
    "Output feature map: $100 \\times 98 \\times 98$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Weight Elements (per filter): $C_{1} \\times K \\times K = 3 \\times 3 \\times 3 = 27$\n",
    "\n",
    "Number of filters $F = 100$\n",
    "\n",
    "Total weights = $27 \\times 100 = 2700$\n",
    "\n",
    "Total bias = $100$\n",
    "\n",
    "Total parameters = $2700 + 100 = 2800$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2.3 (3pts)** Consider an input volume with dimensions 100x100x16, how many parameters\n",
    "does a single 1x1 convolution filter have including the bias term ?\n",
    "\n",
    "Number of filters: $N = 1$\n",
    "\n",
    "convolutional kernel size: $K = 1$\n",
    "\n",
    "Weights per filter: $C_{1} \\times K \\times K = 16 \\times 1 \\times 1 = 16$\n",
    "\n",
    "For a single filter the number of weights is 16 and there is only one bias term per filter so the total parameters is 17."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2.4 (3pts)** Consider the input volume of 100x100x16, and we apply convolution with 32 filters\n",
    "each 5x5 size with a stride of 1 and no padding. What is output shape?\n",
    "\n",
    "Number of filters: $N = 32$\n",
    "\n",
    "convolutional kernel size: $K = 5$\n",
    "\n",
    "Stride for convolution: $S = 1$\n",
    "\n",
    "Padding for each border: $P = 0$\n",
    "\n",
    "$W_{2} = [ \\frac{W_{1}-K+2P}{S}]+1 = [ \\frac{100-5+2*0}{1}]+1 = 96$\n",
    "\n",
    "$H_{2} = [ \\frac{H_{1}-K+2P}{S}]+1 = [ \\frac{100-5+2*0}{1}]+1 = 96$\n",
    "\n",
    "$C_{2} = 32$\n",
    "\n",
    "Output feature map: $32 \\times 96 \\times 96$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2.5 (3pts)** MobileNets use depthwise separable convolution to improve the model efficiency. If\n",
    "we replace all the 3x3 convolution layers to 3x3 depth wise separable convolution layer in ResNet architectures,\n",
    "what would be the likely speedup for these layers. \n",
    "\n",
    "Regular Convolution MACS: $3 \\times 3 \\times M\\times N \\times D_{F} \\times D_{F}$\n",
    "\n",
    "Regular Convolution Parameters: $3 \\times 3 \\times M \\times N$\n",
    "\n",
    "Depthwise Separable Convolution MACS: $3 \\times 3 \\times M \\times D_{F} \\times D_{F} + D_{F} \\times D_{F} \\times M \\times N$\n",
    "\n",
    "Depthwise Separable Convolution Parameters: $3 \\times 3 \\times M + M \\times N$\n",
    "\n",
    "When N,M is large, the speedup is approximately\n",
    "\n",
    "$\\frac{3\\times 3\\times M\\times N \\times D_{F} \\times D_{F}}{3\\times 3\\times M \\times D_{F} \\times D_{F} + D_{F} \\times D_{F} \\times M\\times N} \\approx 9$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
